{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e156d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: processing_intensity_scores.csv\n",
      "      Process  Cluster_KMeans       WCS       EDS      CTDS  \\\n",
      "202  splutter               1  0.512821  0.945197  0.972472   \n",
      "45    deflate               3  0.410256  0.902869  0.921771   \n",
      "223    stream               7  0.320513  0.910002  0.988492   \n",
      "37      crimp               6  0.217949  1.000000  1.000000   \n",
      "73    floured               3  0.423077  0.846296  0.883234   \n",
      "\n",
      "     Processing_Intensity  \n",
      "202              0.811786  \n",
      "45               0.746734  \n",
      "223              0.742157  \n",
      "37               0.741923  \n",
      "73               0.719193  \n",
      "\n",
      "=== CLUSTER INTENSITY RANKING ===\n",
      "Cluster_KMeans\n",
      "3    0.457452\n",
      "4    0.444612\n",
      "6    0.435876\n",
      "7    0.404735\n",
      "0    0.404410\n",
      "1    0.385378\n",
      "2    0.339221\n",
      "5    0.327647\n",
      "Name: Processing_Intensity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "\n",
    "# =====================================================\n",
    "# LOAD INPUT FILES\n",
    "# =====================================================\n",
    "\n",
    "# 1. Load processes from text file\n",
    "with open(\"Process_Clustering_Results/unique_processes_raw.txt\", \"r\") as f:\n",
    "    processes = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "# 2. Load embeddings + cluster labels\n",
    "df_embed = pd.read_csv(\"Process_Clustering_Results/unique_processes_clusters.csv\")\n",
    "\n",
    "# Ensure order matches processes\n",
    "df_embed = df_embed.set_index(\"Process\").loc[processes].reset_index()\n",
    "\n",
    "# Convert embedding string â†’ numpy vector\n",
    "def parse_embedding(s):\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "emb = np.vstack(df_embed[\"Embedding\"].apply(parse_embedding).values)\n",
    "\n",
    "# Use ANY clustering method you want (default KMeans)\n",
    "labels = df_embed[\"KMeans\"].values.astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# 1. WORD COMPLEXITY SCORE\n",
    "# =====================================================\n",
    "\n",
    "def word_complexity(process):\n",
    "    tokens = process.split()\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    suffixes = (\"ize\", \"ise\", \"ify\", \"ation\", \"ated\", \"izing\")\n",
    "    suffix_score = sum(1 for t in tokens if t.endswith(suffixes))\n",
    "\n",
    "    len_score = sum(len(t) for t in tokens)\n",
    "\n",
    "    rarity_score = sum(1.0 / (1 + Counter(t).most_common(1)[0][1])\n",
    "                        for t in tokens)\n",
    "\n",
    "    return 0.4 * len_score + 0.3 * num_tokens + 0.3 * (rarity_score + suffix_score)\n",
    "\n",
    "WCS = np.array([word_complexity(p) for p in processes])\n",
    "\n",
    "# =====================================================\n",
    "# 2. EMBEDDING DISPERSION SCORE\n",
    "# =====================================================\n",
    "\n",
    "vector_norm = np.linalg.norm(emb, axis=1)\n",
    "vector_var = np.var(emb, axis=1)\n",
    "EDS = vector_norm + vector_var\n",
    "\n",
    "# =====================================================\n",
    "# 3. CLUSTER TRANSITION DIFFICULTY\n",
    "# =====================================================\n",
    "\n",
    "global_centroid = np.mean(emb, axis=0)\n",
    "CTDS = np.linalg.norm(emb - global_centroid, axis=1)\n",
    "\n",
    "# =====================================================\n",
    "# NORMALIZE EVERYTHING\n",
    "# =====================================================\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "WCS_n = scaler.fit_transform(WCS.reshape(-1,1)).flatten()\n",
    "EDS_n = scaler.fit_transform(EDS.reshape(-1,1)).flatten()\n",
    "CTDS_n = scaler.fit_transform(CTDS.reshape(-1,1)).flatten()\n",
    "\n",
    "# =====================================================\n",
    "# FINAL PROCESSING INTENSITY SCORE\n",
    "# =====================================================\n",
    "\n",
    "PIS = 0.33 * WCS_n + 0.33 * EDS_n + 0.34 * CTDS_n\n",
    "\n",
    "# =====================================================\n",
    "# SAVE + PRINT RESULTS\n",
    "# =====================================================\n",
    "\n",
    "df_scores = pd.DataFrame({\n",
    "    \"Process\": processes,\n",
    "    \"Cluster_KMeans\": labels,\n",
    "    \"WCS\": WCS_n,\n",
    "    \"EDS\": EDS_n,\n",
    "    \"CTDS\": CTDS_n,\n",
    "    \"Processing_Intensity\": PIS\n",
    "})\n",
    "\n",
    "df_scores_sorted = df_scores.sort_values(\"Processing_Intensity\", ascending=False)\n",
    "df_scores_sorted.to_csv(\"Intensity/processing_intensity_scores.csv\", index=False)\n",
    "\n",
    "print(\"Saved file: processing_intensity_scores.csv\")\n",
    "print(df_scores_sorted.head())\n",
    "\n",
    "# =====================================================\n",
    "# CLUSTER-LEVEL AVERAGE INTENSITY\n",
    "# =====================================================\n",
    "\n",
    "cluster_scores = df_scores.groupby(\"Cluster_KMeans\")[\"Processing_Intensity\"].mean().sort_values(ascending=False)\n",
    "cluster_scores.to_csv(\"Intensity/cluster_intensity_ranking.csv\")\n",
    "\n",
    "print(\"\\n=== CLUSTER INTENSITY RANKING ===\")\n",
    "print(cluster_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
